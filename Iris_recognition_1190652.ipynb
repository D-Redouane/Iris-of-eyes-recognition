{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p>Department Of Computer Science\n","\n","COMP432, COMPUTER SECURITY\n","\n","Dr. Mohammad Alkhanafse\n","\n","Section 2\n","\n","</p>\n","\n","<div align=\"center\">\n","\n","<img src=\"https://github.com/sondosaabed/Introducing-Generative-AI-with-AWS/assets/65151701/01485d19-c6d6-4072-99d7-178ea8ec4364\" alt=\"Birzeit University Logo\" height=\"170px\">\n","\n","\n","# Iris eye Recognition\n","\n","</div>\n","<div align=\"center\">\n","An (End-to-end Identification) Biometric Authentication system using Iris\n","\n","</div>\n","\n","<b>Prepared by:</b> Sondos Aabed\n","\n","<b>Studnet ID:</b> 1190652\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Abstract\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Table of Contents\n","- Introduction\n","    - About Dataset Used\n","    - Aim and Objectives\n","    - Methodology\n","- Theory\n","- Software Listing\n","- Implementation\n","    - Dataset Analysis\n","    - Data Modeling\n","    - GUI\n","- Conclusion\n","- Refrences\n","\n","## List of Figures\n","\n","## List of Tables\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","The Iris-Recongtion has been widely used in identication, for many resons : [1]\n","1. `Unique:` there are not any iris having the same physical characteristic as others, even if they come from the same person or identical twins; \n","2. `Stability:` the iris is formed during childhood, and it generally maintains unchangeable physical characteristics throughout life; \n","3. `Informative:` the iris has rich texture information such as spots, stripes, \flaments and coronas.\n","4. `Safety:` Since the iris is located in a circular area under the surface of the eye between the black pupil and the white sclera, it is rarely disturbed by external factors. As a result, it is di\u000ecult to forge the iris pattern; \n","5. `Contactless:` Iris Recognition (IR) is more hygienic than biometrics that requires contact, such as fngerprint recognition.\n"," \n","\n","### About Dataset used\n","\n","CASIA-V4-Distance contains 2,567 images from 142 subjects. These images were obtained using near-infrared imaging techniques. Subjects were located three meters away from the camera. The resolution of the iris images is 2,352 \u0002 1,728 pixels. Each sample in the dataset contains the upper part of the face, which includes irises and other facial details. These details, such as skin lines, can be used for multi-modal biometric information fusion. This is a publicly available long-range and high-quality iris and facial dataset."]},{"cell_type":"markdown","metadata":{},"source":["### Aim and Objectives\n","\n","- To design a biometric based authentication system.\n","- To perform data analysis on Iris Dataset\n","- To perfrom data modeling as a user recognition task (Verifier Module) \n","- To build an enrollment module (Enrollment Module)"]},{"cell_type":"markdown","metadata":{},"source":["### Methodogly \n","\n","The approach in this implenetauion, is an end-to-end identifiation of Iris using Deep learning. Where a base model is used as the Feature extractor and the Dense softmax are used for the classification task.\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Theory\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Software Listing\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Implemetation\n","\n","In this section, the aim and objectives are met and presented. First the dataset is looked into and decisions are made based on that, then the model archeiticure is prepared and finally the enrollment module is used and the model is integrated into it.\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{},"source":["Necceary imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:57:59.656357Z","iopub.status.busy":"2024-04-24T15:57:59.655907Z","iopub.status.idle":"2024-04-24T15:58:13.406006Z","shell.execute_reply":"2024-04-24T15:58:13.405192Z","shell.execute_reply.started":"2024-04-24T15:57:59.656325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-24 15:58:02.257239: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-24 15:58:02.257341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-24 15:58:02.429938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import PIL\n","import tensorflow as tf\n","from keras import backend as K\n","from tensorflow import keras as keras\n","import matplotlib.pyplot as plt\n","from keras import Sequential\n","import random\n","from keras.layers import InputLayer,Activation,Dense,Dropout, Conv2D, BatchNormalization, Flatten, MaxPooling2D, Input, Reshape, Concatenate"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Analysis"]},{"cell_type":"markdown","metadata":{},"source":["#### Loading Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:58:21.794321Z","iopub.status.busy":"2024-04-24T15:58:21.793194Z","iopub.status.idle":"2024-04-24T15:58:21.801098Z","shell.execute_reply":"2024-04-24T15:58:21.800114Z","shell.execute_reply.started":"2024-04-24T15:58:21.794286Z"},"trusted":true},"outputs":[],"source":["def load_dataset(path):\n","    \"\"\"\n","    Args:\n","        path(str): string that has the path of the dataset\n","    Returns:\n","        df(pd.DataFrame): the loaded dataframe\n","    \"\"\"\n","    labels = []\n","    images = []\n","\n","    for folder in os.listdir(path):\n","        for image in os.listdir(path+'/'+folder):\n","            if image.endswith('b') is False:\n","                images.append(path+'/'+folder+'/'+image)\n","                labels.append(folder)\n","\n","    df = pd.DataFrame(list(zip(labels, images)), columns=['Label', 'ImagePath'])\n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:58:24.362575Z","iopub.status.busy":"2024-04-24T15:58:24.361820Z","iopub.status.idle":"2024-04-24T15:58:25.414990Z","shell.execute_reply":"2024-04-24T15:58:25.414240Z","shell.execute_reply.started":"2024-04-24T15:58:24.362539Z"},"trusted":true},"outputs":[],"source":["df = load_dataset('/kaggle/input/casia-iris-distance/CASIA-Iris-Distance')"]},{"cell_type":"markdown","metadata":{},"source":["#### Expolring Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:58:27.411476Z","iopub.status.busy":"2024-04-24T15:58:27.410794Z","iopub.status.idle":"2024-04-24T15:58:27.416796Z","shell.execute_reply":"2024-04-24T15:58:27.415854Z","shell.execute_reply.started":"2024-04-24T15:58:27.411442Z"},"trusted":true},"outputs":[],"source":["def missing_values(df):\n","    \"\"\"\n","    This is to get the percetages of missing data\n","    Args:\n","        df (pd.Dataframe): contains the data\n","    Returns:\n","        missing_percetanges(pd.Dataframe): contains Column,\tCounts, and\tPercentage\n","            of the missing values for eah colmn\n","    \"\"\"\n","    missing_count = df.isnull().sum()\n","    missing_percetanges = pd.DataFrame({\n","        'Column': missing_count.index,\n","        'Counts': missing_count.values,\n","        'Percentage': missing_count.values / len(df) * 100  \n","    })\n","    return  missing_percetanges"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:58:29.628647Z","iopub.status.busy":"2024-04-24T15:58:29.627790Z","iopub.status.idle":"2024-04-24T15:58:29.635272Z","shell.execute_reply":"2024-04-24T15:58:29.634307Z","shell.execute_reply.started":"2024-04-24T15:58:29.628612Z"},"trusted":true},"outputs":[],"source":["def explore_data(df):\n","    \"\"\"\n","    Exploring a dataset sample\n","    Args:\n","        sample (pd.Dataframe): the dataset sample to explore.\n","    Returns:\n","        results (dict): containing results of each exploration with the title as key\n","    \"\"\"\n","    head = pd.DataFrame(df.head())\n","    tail = pd.DataFrame(df.tail())\n","    nunique = pd.DataFrame(df.nunique(), columns=[\"#_of_Unique\"])\n","    describe = pd.DataFrame(df.describe())\n","    dtypes =  pd.DataFrame(df.dtypes, columns=[\"Datatype\"])\n","    results = {\n","        'Table 3: Dataset Head:':head,\n","        'Table 4: Dataset Tail:':tail,\n","        'Table 5: Dataset Numerical Describtion: ':describe,\n","        'Table 6: Missing Values By Percentage': missing_values(df), \n","        'Table 7: Dataset Columns Data types: ':dtypes,\n","        'Table 8: Number of uniques in the datasets:':nunique}\n","    return results"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:58:32.648192Z","iopub.status.busy":"2024-04-24T15:58:32.647419Z","iopub.status.idle":"2024-04-24T15:58:32.653432Z","shell.execute_reply":"2024-04-24T15:58:32.652363Z","shell.execute_reply.started":"2024-04-24T15:58:32.648161Z"},"trusted":true},"outputs":[],"source":["def print_sample_exploration(results):\n","    \"\"\"\n","    Prints a beautufil display of each of the exploration dataframe\n","    Args:\n","        results (dict): contains exploration outputs with the title as key\n","    Returns:\n","        nothing\n","    \"\"\"\n","    for operation, dataframe in results.items():\n","        print(f\"{operation}\")\n","        if operation == 'Table 6: Missing Values By Percentage':\n","            print(\"Total Sum of Missing Percetange: \", dataframe['Percentage'].sum())\n","        display(dataframe)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T15:58:35.368051Z","iopub.status.busy":"2024-04-24T15:58:35.367246Z","iopub.status.idle":"2024-04-24T15:58:35.432398Z","shell.execute_reply":"2024-04-24T15:58:35.431559Z","shell.execute_reply.started":"2024-04-24T15:58:35.368016Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Table 3: Dataset Head:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>ImagePath</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>135</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>135</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>135</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>135</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>135</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Label                                          ImagePath\n","0   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","1   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","2   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","3   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","4   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D..."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Table 4: Dataset Tail:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>ImagePath</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2562</th>\n","      <td>085</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>2563</th>\n","      <td>085</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>2564</th>\n","      <td>085</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>2565</th>\n","      <td>085</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>2566</th>\n","      <td>085</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Label                                          ImagePath\n","2562   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","2563   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","2564   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","2565   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","2566   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D..."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Table 5: Dataset Numerical Describtion: \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>ImagePath</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2567</td>\n","      <td>2567</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>142</td>\n","      <td>2567</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>074</td>\n","      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>23</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Label                                          ImagePath\n","count   2567                                               2567\n","unique   142                                               2567\n","top      074  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n","freq      23                                                  1"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Table 6: Missing Values By Percentage\n","Total Sum of Missing Percetange:  0.0\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Column</th>\n","      <th>Counts</th>\n","      <th>Percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Label</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ImagePath</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Column  Counts  Percentage\n","0      Label       0         0.0\n","1  ImagePath       0         0.0"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Table 7: Dataset Columns Data types: \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datatype</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Label</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>ImagePath</th>\n","      <td>object</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Datatype\n","Label       object\n","ImagePath   object"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Table 8: Number of uniques in the datasets:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>#_of_Unique</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Label</th>\n","      <td>142</td>\n","    </tr>\n","    <tr>\n","      <th>ImagePath</th>\n","      <td>2567</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           #_of_Unique\n","Label              142\n","ImagePath         2567"]},"metadata":{},"output_type":"display_data"}],"source":["print_sample_exploration(explore_data(df))"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T17:11:07.140217Z","iopub.status.busy":"2024-04-25T17:11:07.139889Z","iopub.status.idle":"2024-04-25T17:11:07.155794Z","shell.execute_reply":"2024-04-25T17:11:07.154854Z","shell.execute_reply.started":"2024-04-25T17:11:07.140190Z"},"trusted":true},"outputs":[],"source":["def show_random_samples(df, num):\n","    \"\"\"\n","    Shows a sample on the dataframe in a specific location.\n","    Args:\n","        df (pd.DataFrame): teh datset\n","        location(int): the location of the sample to be shown\n","    Return:\n","        Nothing but shows a sample in the display\n","    \"\"\"\n","    random_indices = random.sample(range(df.shape[0]), num)\n","\n","    for i, idx in enumerate(random_indices):\n","        image_path = df.loc[idx,\"ImagePath\"]\n","        image = Image.open(image_path)\n","        fig = plt.figure(figsize=(image.width/10, image.height))\n","        ax = fig.add_subplot(1, 8, i +1)\n","        ax.imshow(image, extent=[0,  image.width/10, 0,  image.height/10])\n","        ax.set_title(f\"Image {idx}\")\n","        ax.axis(\"off\")\n","        plt.show()\n","        print(f\"Image {idx} Latin Label: {df['Label']}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing Dataset"]},{"cell_type":"markdown","metadata":{},"source":["##### Images preparing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_images(df):\n","    \"\"\"\n","    \n","    \"\"\""]},{"cell_type":"markdown","metadata":{},"source":["##### labels preparing:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_labels(df):\n","    \"\"\"\n","    \n","    \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepare_dataset(df):\n","    \"\"\"\n","    \n","    \"\"\"\n","    images = preprocess_images(df)\n","    labels = preprocess_labels(df)\n","    return images, labels"]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["### Data modeling (The Verifier)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Archeticticure:"]},{"cell_type":"markdown","metadata":{},"source":["##### Base model (Feature Extracture)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["activation =''\n","padding = ''\n","poolpadding = ''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def feature_extraction(input_img, input_shape= (800, 64, 1)):\n","    \"\"\"\n","    Args:\n","        takes the input image size\n","    \n","    Returns:\n","        features of that image\n","    \n","    \"\"\"\n","    conv1 = Conv2D(64, (5, 5), padding=padding, name=\"conv1\")(input_img)\n","    act1 = Activation(activation)(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2), padding=poolpadding, name=\"pool1\")(act1)\n","    x = Dropout(0.1, name=\"dropout\")(pool1)\n","    \n","    conv2 = Conv2D(128, (5, 5), padding=padding, name=\"conv2\")(x)\n","    act2 = Activation(activation)(conv2)\n","    pool2 = MaxPooling2D(pool_size=(1, 2), padding=poolpadding, name=\"pool2\")(act2)\n","    x = Dropout(0.2, name=\"dropout1\")(pool2)\n","    \n","    conv3 = Conv2D(128, (3, 3), padding=padding, name=\"conv3\")(x)\n","    act3 = Activation(activation)(conv3)\n","    batch_norm3 = BatchNormalization(name=\"BatchNorm1\")(act3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2), padding=poolpadding, name=\"pool3\")(batch_norm3)\n","    x = Dropout(0.25, name=\"dropout2\")(pool3)\n","    \n","    conv4 = Conv2D(256, (3, 3), padding=padding, name=\"conv4\")(x)\n","    act4 = Activation(activation)(conv4)\n","    x = Dropout(0.3, name=\"dropout3\")(act4)\n","    \n","    conv5 = Conv2D(256, (3, 3), padding=padding, name=\"conv5\")(x)\n","    act5 = Activation(activation)(conv5)\n","    pool5 = MaxPooling2D(pool_size=(2, 2), padding=poolpadding, name=\"pool4\")(act5)\n","    x = Dropout(0.35, name=\"dropout4\")(pool5)\n","\n","    conv6 = Conv2D(512, (3, 3), padding=padding, name=\"conv6\")(pool5)\n","    act6 = Activation(activation)(conv6)\n","    batch_norm6 = BatchNormalization(name=\"BatchNorm2\")(act6)\n","    pool6 = MaxPooling2D(pool_size=(1, 2), padding=poolpadding, name=\"pool5\")(batch_norm6)\n","    x = Dropout(0.4, name=\"dropout5\")(pool6)\n","    \n","    conv7 = Conv2D(512, (3, 3), padding=padding, name=\"conv7\")(x)\n","    act7 = Activation(activation)(conv7)\n","    pool7 = MaxPooling2D(pool_size=(1, 2), padding=poolpadding, name=\"pool6\")(act7)\n","    x = Dropout(0.45, name=\"dropout6\")(pool7)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def recognition_model(optimizer='sgd',learning_rate=1e-2, input_shape=(64, 800, 1), activation='leaky_relu'):\n","    \"\"\"\n","    Takes two args: \n","        (optimizer): to test on diffrent optimizers\n","        (activation): to test on diffrent activations\n","    Returns:\n","        (model) a model compiled with it's layers\n","    \"\"\"\n","    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n","    model = Sequential()\n","    model.add(InputLayer(input_shape=input_shape, name='input_image'))\n","    model.add(Flatten())\n","    model.add(Dense(142, activation='softmax', name='output_sentence'))\n","    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["#### Recognition model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def reconition_model(featurres):\n","    \"\"\"\n","    \n","    \"\"\""]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and testing:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Model Evaluaion metrics:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["### User Experinece and GUI (The Authenticater)"]},{"cell_type":"markdown","metadata":{},"source":["#### Image Accuisition (for enrollment)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Image Accuisition (for authentication)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Image Preparing for Recognition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def input_image_preprocesisng(image):\n","    \"\"\"\n","    \n","    \"\"\""]},{"cell_type":"markdown","metadata":{},"source":["#### Model Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion"]},{"cell_type":"markdown","metadata":{},"source":["## Refrences\n","- [1] [Deep Learning for Iris Recognition: A Review, Yin, Y., He, S., Zhang, R., Chang, H., Han, X., & Zhang, J. (2024)](https://arxiv.org/abs/2303.08514)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4865182,"sourceId":8209871,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
