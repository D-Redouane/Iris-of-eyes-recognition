{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8209871,"sourceType":"datasetVersion","datasetId":4865182}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p>Department Of Computer Science\n\nCOMP432, COMPUTER SECURITY\n\nDr. Mohammad Alkhanafse\n\nSection 2\n\n</p>\n\n<div align=\"center\">\n\n<img src=\"https://github.com/sondosaabed/Introducing-Generative-AI-with-AWS/assets/65151701/01485d19-c6d6-4072-99d7-178ea8ec4364\" alt=\"Birzeit University Logo\" height=\"170px\">\n\n\n# Iris eye Recognition\n\n</div>\n<div align=\"center\">\nAn (End-to-end Identification) Biometric Authentication system using Iris\n\n</div>\n\n<b>Prepared by:</b> Sondos Aabed\n\n<b>Studnet ID:</b> 1190652\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Abstract\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n## List of Figures\n\n## List of Tables\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nThe Iris-Recongtion has been widely used in identication, for many resons : [1]\n1. `Unique:` there are not any iris having the same physical characteristic as others, even if they come from the same person or identical twins; \n2. `Stability:` the iris is formed during childhood, and it generally maintains unchangeable physical characteristics throughout life; \n3. `Informative:` the iris has rich texture information such as spots, stripes, \flaments and coronas.\n4. `Safety:` Since the iris is located in a circular area under the surface of the eye between the black pupil and the white sclera, it is rarely disturbed by external factors. As a result, it is di\u000ecult to forge the iris pattern; \n5. `Contactless:` Iris Recognition (IR) is more hygienic than biometrics that requires contact, such as fngerprint recognition.\n \n\n### About Dataset used\n\nCASIA-V4-Distance contains 2,567 images from 142 subjects. These images were obtained using near-infrared imaging techniques. Subjects were located three meters away from the camera. The resolution of the iris images is 2,352 \u0002 1,728 pixels. Each sample in the dataset contains the upper part of the face, which includes irises and other facial details. These details, such as skin lines, can be used for multi-modal biometric information fusion. This is a publicly available long-range and high-quality iris and facial dataset.","metadata":{}},{"cell_type":"markdown","source":"### Aim and Objectives\n\n- To design a biometric based authentication system.\n- To perform data analysis on Iris Dataset\n- To perfrom data modeling as a user recognition task (Verifier Module) \n- To build an enrollment module (Enrollment Module)","metadata":{}},{"cell_type":"markdown","source":"### Methodogly \n\nThe approach in this implenetauion, is an end-to-end identifiation of Iris using Deep learning. Where a base model is used as the Feature extractor and the Dense softmax are used for the classification task.\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Theory\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Software Listing\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Implemetation\n\nIn this section, the aim and objectives are met and presented. First the dataset is looked into and decisions are made based on that, then the model archeiticure is prepared and finally the enrollment module is used and the model is integrated into it.\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"Necceary imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:57:59.655907Z","iopub.execute_input":"2024-04-24T15:57:59.656357Z","iopub.status.idle":"2024-04-24T15:58:13.406006Z","shell.execute_reply.started":"2024-04-24T15:57:59.656325Z","shell.execute_reply":"2024-04-24T15:58:13.405192Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-24 15:58:02.257239: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-24 15:58:02.257341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-24 15:58:02.429938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset Analysis","metadata":{}},{"cell_type":"markdown","source":"#### Loading Dataset","metadata":{}},{"cell_type":"code","source":"def load_dataset(path):\n    \"\"\"\n    Args:\n        path(str): string that has the path of the dataset\n    Returns:\n        df(pd.DataFrame): the loaded dataframe\n    \"\"\"\n    labels = []\n    images = []\n\n    for folder in os.listdir(path):\n        for image in os.listdir(path+'/'+folder):\n            if image.endswith('b') is False:\n                images.append(path+'/'+folder+'/'+image)\n                labels.append(folder)\n\n    df = pd.DataFrame(list(zip(labels, images)), columns=['Label', 'ImagePath'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:58:21.793194Z","iopub.execute_input":"2024-04-24T15:58:21.794321Z","iopub.status.idle":"2024-04-24T15:58:21.801098Z","shell.execute_reply.started":"2024-04-24T15:58:21.794286Z","shell.execute_reply":"2024-04-24T15:58:21.800114Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = load_dataset('/kaggle/input/casia-iris-distance/CASIA-Iris-Distance')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:58:24.361820Z","iopub.execute_input":"2024-04-24T15:58:24.362575Z","iopub.status.idle":"2024-04-24T15:58:25.414990Z","shell.execute_reply.started":"2024-04-24T15:58:24.362539Z","shell.execute_reply":"2024-04-24T15:58:25.414240Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Expolring Dataset","metadata":{}},{"cell_type":"code","source":"def missing_values(df):\n    \"\"\"\n    This is to get the percetages of missing data\n    Args:\n        df (pd.Dataframe): contains the data\n    Returns:\n        missing_percetanges(pd.Dataframe): contains Column,\tCounts, and\tPercentage\n            of the missing values for eah colmn\n    \"\"\"\n    missing_count = df.isnull().sum()\n    missing_percetanges = pd.DataFrame({\n        'Column': missing_count.index,\n        'Counts': missing_count.values,\n        'Percentage': missing_count.values / len(df) * 100  \n    })\n    return  missing_percetanges","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:58:27.410794Z","iopub.execute_input":"2024-04-24T15:58:27.411476Z","iopub.status.idle":"2024-04-24T15:58:27.416796Z","shell.execute_reply.started":"2024-04-24T15:58:27.411442Z","shell.execute_reply":"2024-04-24T15:58:27.415854Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def explore_data(df):\n    \"\"\"\n    Exploring a dataset sample\n    Args:\n        sample (pd.Dataframe): the dataset sample to explore.\n    Returns:\n        results (dict): containing results of each exploration with the title as key\n    \"\"\"\n    head = pd.DataFrame(df.head())\n    tail = pd.DataFrame(df.tail())\n    nunique = pd.DataFrame(df.nunique(), columns=[\"#_of_Unique\"])\n    describe = pd.DataFrame(df.describe())\n    dtypes =  pd.DataFrame(df.dtypes, columns=[\"Datatype\"])\n    results = {\n        'Table 3: Dataset Head:':head,\n        'Table 4: Dataset Tail:':tail,\n        'Table 5: Dataset Numerical Describtion: ':describe,\n        'Table 6: Missing Values By Percentage': missing_values(df), \n        'Table 7: Dataset Columns Data types: ':dtypes,\n        'Table 8: Number of uniques in the datasets:':nunique}\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:58:29.627790Z","iopub.execute_input":"2024-04-24T15:58:29.628647Z","iopub.status.idle":"2024-04-24T15:58:29.635272Z","shell.execute_reply.started":"2024-04-24T15:58:29.628612Z","shell.execute_reply":"2024-04-24T15:58:29.634307Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def print_sample_exploration(results):\n    \"\"\"\n    Prints a beautufil display of each of the exploration dataframe\n    Args:\n        results (dict): contains exploration outputs with the title as key\n    Returns:\n        nothing\n    \"\"\"\n    for operation, dataframe in results.items():\n        print(f\"{operation}\")\n        if operation == 'Table 6: Missing Values By Percentage':\n            print(\"Total Sum of Missing Percetange: \", dataframe['Percentage'].sum())\n        display(dataframe)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:58:32.647419Z","iopub.execute_input":"2024-04-24T15:58:32.648192Z","iopub.status.idle":"2024-04-24T15:58:32.653432Z","shell.execute_reply.started":"2024-04-24T15:58:32.648161Z","shell.execute_reply":"2024-04-24T15:58:32.652363Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print_sample_exploration(explore_data(df))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:58:35.367246Z","iopub.execute_input":"2024-04-24T15:58:35.368051Z","iopub.status.idle":"2024-04-24T15:58:35.432398Z","shell.execute_reply.started":"2024-04-24T15:58:35.368016Z","shell.execute_reply":"2024-04-24T15:58:35.431559Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Table 3: Dataset Head:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Label                                          ImagePath\n0   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n1   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n2   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n3   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n4   135  /kaggle/input/casia-iris-distance/CASIA-Iris-D...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>ImagePath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>135</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>135</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>135</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>135</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>135</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Table 4: Dataset Tail:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     Label                                          ImagePath\n2562   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n2563   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n2564   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n2565   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\n2566   085  /kaggle/input/casia-iris-distance/CASIA-Iris-D...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>ImagePath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2562</th>\n      <td>085</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>2563</th>\n      <td>085</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>2564</th>\n      <td>085</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>2565</th>\n      <td>085</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>2566</th>\n      <td>085</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Table 5: Dataset Numerical Describtion: \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       Label                                          ImagePath\ncount   2567                                               2567\nunique   142                                               2567\ntop      074  /kaggle/input/casia-iris-distance/CASIA-Iris-D...\nfreq      23                                                  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>ImagePath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2567</td>\n      <td>2567</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>142</td>\n      <td>2567</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>074</td>\n      <td>/kaggle/input/casia-iris-distance/CASIA-Iris-D...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>23</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Table 6: Missing Values By Percentage\nTotal Sum of Missing Percetange:  0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Column  Counts  Percentage\n0      Label       0         0.0\n1  ImagePath       0         0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Counts</th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Label</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ImagePath</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Table 7: Dataset Columns Data types: \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          Datatype\nLabel       object\nImagePath   object","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datatype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Label</th>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>ImagePath</th>\n      <td>object</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Table 8: Number of uniques in the datasets:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           #_of_Unique\nLabel              142\nImagePath         2567","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#_of_Unique</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Label</th>\n      <td>142</td>\n    </tr>\n    <tr>\n      <th>ImagePath</th>\n      <td>2567</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def show_random_samples(df, num):\n    \"\"\"\n    Shows a sample on the dataframe in a specific location.\n    Args:\n        df (pd.DataFrame): teh datset\n        location(int): the location of the sample to be shown\n    Return:\n        Nothing but shows a sample in the display\n    \"\"\"\n    random_indices = random.sample(range(df.shape[0]), num)\n\n    for i, idx in enumerate(random_indices):\n        image_path = df.loc[idx,\"ImagePath\"]\n        image = Image.open(image_path)\n        fig = plt.figure(figsize=(image.width/10, image.height))\n        ax = fig.add_subplot(1, 8, i +1)\n        ax.imshow(image, extent=[0,  image.width/10, 0,  image.height/10])\n        ax.set_title(f\"Image {idx}\")\n        ax.axis(\"off\")\n        plt.show()\n        print(f\"Image {idx} Latin Label: {df['Label']}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:11:07.139889Z","iopub.execute_input":"2024-04-25T17:11:07.140217Z","iopub.status.idle":"2024-04-25T17:11:07.155794Z","shell.execute_reply.started":"2024-04-25T17:11:07.140190Z","shell.execute_reply":"2024-04-25T17:11:07.154854Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### Preparing Dataset","metadata":{}},{"cell_type":"markdown","source":"##### Images preparing","metadata":{}},{"cell_type":"code","source":"def preprocess_images(df):\n    \"\"\"\n    \n    \"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### labels preparing:","metadata":{}},{"cell_type":"code","source":"def preprocess_labels(df):\n    \"\"\"\n    \n    \"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(df):\n    \"\"\"\n    \n    \"\"\"\n    images = preprocess_images(df)\n    labels = preprocess_labels(df)\n    return images, labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr>","metadata":{}},{"cell_type":"markdown","source":"### Data modeling (The Verifier)","metadata":{}},{"cell_type":"markdown","source":"#### Model Archeticticure:","metadata":{}},{"cell_type":"markdown","source":"##### Base model (Feature Extracture)","metadata":{}},{"cell_type":"code","source":"def feature_extraction(input_img, input_shape= (800, 64, 1)):\n    \"\"\"\n    Args:\n        takes the input image size\n    \n    Returns:\n        features of that image\n    \n    \"\"\"\n    conv1 = Conv2D(64, (5, 5), padding=padding, name=\"conv1\")(input_img)\n    act1 = Activation(activation)(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2), padding=poolpadding, name=\"pool1\")(act1)\n    x = Dropout(0.1, name=\"dropout\")(pool1)\n    \n    conv2 = Conv2D(128, (5, 5), padding=padding, name=\"conv2\")(x)\n    act2 = Activation(activation)(conv2)\n    pool2 = MaxPooling2D(pool_size=(1, 2), padding=poolpadding, name=\"pool2\")(act2)\n    x = Dropout(0.2, name=\"dropout1\")(pool2)\n    \n    conv3 = Conv2D(128, (3, 3), padding=padding, name=\"conv3\")(x)\n    act3 = Activation(activation)(conv3)\n    batch_norm3 = BatchNormalization(name=\"BatchNorm1\")(act3)\n    pool3 = MaxPooling2D(pool_size=(2, 2), padding=poolpadding, name=\"pool3\")(batch_norm3)\n    x = Dropout(0.25, name=\"dropout2\")(pool3)\n    \n    conv4 = Conv2D(256, (3, 3), padding=padding, name=\"conv4\")(x)\n    act4 = Activation(activation)(conv4)\n    x = Dropout(0.3, name=\"dropout3\")(act4)\n    \n    conv5 = Conv2D(256, (3, 3), padding=padding, name=\"conv5\")(x)\n    act5 = Activation(activation)(conv5)\n    pool5 = MaxPooling2D(pool_size=(2, 2), padding=poolpadding, name=\"pool4\")(act5)\n    x = Dropout(0.35, name=\"dropout4\")(pool5)\n\n    conv6 = Conv2D(512, (3, 3), padding=padding, name=\"conv6\")(pool5)\n    act6 = Activation(activation)(conv6)\n    batch_norm6 = BatchNormalization(name=\"BatchNorm2\")(act6)\n    pool6 = MaxPooling2D(pool_size=(1, 2), padding=poolpadding, name=\"pool5\")(batch_norm6)\n    x = Dropout(0.4, name=\"dropout5\")(pool6)\n    \n    conv7 = Conv2D(512, (3, 3), padding=padding, name=\"conv7\")(x)\n    act7 = Activation(activation)(conv7)\n    pool7 = MaxPooling2D(pool_size=(1, 2), padding=poolpadding, name=\"pool6\")(act7)\n    x = Dropout(0.45, name=\"dropout6\")(pool7)\n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recognition_model(optimizer='sgd',learning_rate=1e-2, input_shape=(64, 800, 1), activation='leaky_relu'):\n    \"\"\"\n    Takes two args: \n        (optimizer): to test on diffrent optimizers\n        (activation): to test on diffrent activations\n    Returns:\n        (model) a model compiled with it's layers\n    \"\"\"\n\n    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n    \n    model = Sequential()\n    model.add(InputLayer(input_shape=input_shape, name='input_image'))\n\n    model.add(Flatten())\n    model.add(Dense(len(classes), activation='softmax', name='output_sentence'))\n    \n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Recognition model","metadata":{}},{"cell_type":"code","source":"def reconition_model(featurres):\n    \"\"\"\n    \n    \"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Training and testing:","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Evaluaion metrics:","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr>","metadata":{}},{"cell_type":"markdown","source":"### User Experinece and GUI (The Authenticater)","metadata":{}},{"cell_type":"markdown","source":"#### Image Accuisition (for enrollment)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Image Accuisition (for authentication)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Image Preparing for Recognition","metadata":{}},{"cell_type":"code","source":"def input_image_preprocesisng(image):\n    \"\"\"\n    \n    \"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Inference","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr>","metadata":{}},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"## Refrences\n- [1] [Deep Learning for Iris Recognition: A Review, Yin, Y., He, S., Zhang, R., Chang, H., Han, X., & Zhang, J. (2024)](https://arxiv.org/abs/2303.08514)","metadata":{}}]}